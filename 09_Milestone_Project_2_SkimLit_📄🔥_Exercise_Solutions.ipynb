{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ljg02WzOHZ9"
      },
      "source": [
        "1. Train `model_5` on all of the data in the training dataset for as many epochs until it stops improving. Since this might take a while, you might want to use:\n",
        "  * [`tf.keras.callbacks.ModelCheckpoint`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint) to save the model's best weights only.\n",
        "\n",
        "  * [`tf.keras.callbacks.EarlyStopping`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) to stop the model from training once the validation loss has stopped improving for ~3 epochs.\n",
        "\n",
        "\n",
        "2. Checkout the [Keras guide on using pretrained GloVe embeddings](https://keras.io/examples/nlp/pretrained_word_embeddings/). Can you get this working with one of our models?\n",
        "  *   Hint: You'll want to incorporate it with a custom token [Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) layer.\n",
        "\n",
        "  *  It's up to you whether or not you fine-tune the GloVe embeddings or leave them frozen.\n",
        "\n",
        "\n",
        "3. Try replacing the TensorFlow Hub Universal Sentence Encoder pretrained  embedding for the [TensorFlow Hub BERT PubMed expert](https://tfhub.dev/google/experts/bert/pubmed/2) (a language model pretrained on PubMed texts) pretrained embedding. Does this effect results?\n",
        "  *  Note: Using the BERT PubMed expert pretrained embedding requires an extra preprocessing step for sequences (as detailed in the [TensorFlow Hub guide](https://tfhub.dev/google/experts/bert/pubmed/2)).\n",
        "  \n",
        "  *  Does the BERT model beat the results mentioned in this paper? https://arxiv.org/pdf/1710.06071.pdf\n",
        "\n",
        "4. What happens if you were to merge our `line_number` and `total_lines` features for each sequence? For example, created a `X_of_Y` feature instead? Does this effect model performance?\n",
        "   *  Another example: `line_number=1` and `total_lines=11` turns into `line_of_X=1_of_11`.\n",
        "        \n",
        "\n",
        "5. Write a function (or series of functions) to take a sample abstract string, preprocess it (in the same way our model has been trained), make a prediction on each sequence in the abstract and return the abstract in the format:\n",
        "   *  `PREDICTED_LABEL`: `SEQUENCE`\n",
        "  \n",
        "   *  `PREDICTED_LABEL`: `SEQUENCE`\n",
        "  \n",
        "   *  `PREDICTED_LABEL`: `SEQUENCE`\n",
        "  \n",
        "   *  `PREDICTED_LABEL`: `SEQUENCE`\n",
        "  \n",
        "   *  ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c_Hg5u0IQDz",
        "outputId": "5c44bd44-9288-4603-db70-d919c497be47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.15.0\n",
            "  Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.11/dist-packages (0.16.1)\n",
            "Collecting keras==2.15.0\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.18.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (25.1.21)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (18.1.1)\n",
            "Collecting ml-dtypes~=0.2.0 (from tensorflow==2.15.0)\n",
            "  Downloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.0)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.69.0)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.0)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.0)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub) (2.17.0)\n",
            "INFO: pip is looking at multiple versions of tensorflow-text to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "  Downloading tensorflow_text-2.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "  Downloading tensorflow_text-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "  Downloading tensorflow_text-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.1.3)\n",
            "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf-keras>=2.14.1 (from tensorflow-hub)\n",
            "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n",
            "Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_text-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_keras-2.15.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, ml-dtypes, keras, tensorboard, tensorflow, tf-keras, tensorflow_text\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.5.0\n",
            "    Uninstalling keras-3.5.0:\n",
            "      Successfully uninstalled keras-3.5.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "  Attempting uninstall: tf-keras\n",
            "    Found existing installation: tf_keras 2.17.0\n",
            "    Uninstalling tf_keras-2.17.0:\n",
            "      Successfully uninstalled tf_keras-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorstore 0.1.71 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.15.0 ml-dtypes-0.2.0 tensorboard-2.15.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow_text-2.15.0 tf-keras-2.15.1 wrapt-1.14.1\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.15.0 tensorflow-hub keras==2.15.0 tensorflow_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpVRH70ROHZ_"
      },
      "source": [
        "## Downloading the data and preprocessing it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tr-gXrQlOHZ_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1ytPoOyfLdAd",
        "outputId": "82dc8e6d-cb0d-4cd7-e610-c129041dda42"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.15.0'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJlL5lxqOHZ_",
        "outputId": "b60751a8-770f-4954-c64d-bc351c67b119"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 39 (delta 8), reused 5 (delta 5), pack-reused 25 (from 1)\u001b[K\n",
            "Receiving objects: 100% (39/39), 177.08 MiB | 15.47 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Updating files: 100% (13/13), done.\n",
            "PubMed_200k_RCT\t\t\t\t       PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign  README.md\n",
            "PubMed_20k_RCT\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n",
        "!ls pubmed-rct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1RQ20u49OHZ_"
      },
      "outputs": [],
      "source": [
        "# Start by using the 20k dataset\n",
        "data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w0QCBmLOHaA",
        "outputId": "4be9def8-b30a-4215-b16a-b3b0fb2dfbb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check all of the filenames in the target directory\n",
        "import os\n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "q2GhewUAOHaA"
      },
      "outputs": [],
      "source": [
        "# Create function to read the lines of a document\n",
        "def get_lines(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        return f.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LPTwYEhgOHaA"
      },
      "outputs": [],
      "source": [
        "def preprocess_text_with_line_numbers(filename):\n",
        "    input_lines = get_lines(filename) # Get all lines from filename\n",
        "    abstract_lines = \"\" # Create an empty abstract\n",
        "    abstract_samples = [] # Create an empty list of abstracts\n",
        "\n",
        "    # Loop through each line in the target file\n",
        "    for line in input_lines:\n",
        "        if line.startswith(\"###\"): # Check to see if there is an ID line\n",
        "            abstract_id = line\n",
        "            abstract_lines = \"\" # Reset the abstract string if the line is an ID line\n",
        "        elif line.isspace(): # Check to see if the line is a new line\n",
        "            abstract_line_split = abstract_lines.splitlines() # Split abstract into separate lines\n",
        "\n",
        "            # Iterate through each line in a single abstract and count them at the same time\n",
        "            for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "                line_data = {} # Create an empty dictionary for each line\n",
        "                target_text_split = abstract_line.split(\"\\t\") # Split target label from the text\n",
        "                line_data[\"target\"] = target_text_split[0]\n",
        "                line_data[\"text\"] = target_text_split[1].lower()\n",
        "                line_data[\"line_number\"] = abstract_line_number\n",
        "                line_data[\"total_lines\"] = len(abstract_line_split) - 1\n",
        "                abstract_samples.append(line_data) # Add line data to abstract samples list\n",
        "        else:\n",
        "            abstract_lines += line\n",
        "\n",
        "    return abstract_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lU9y10D8OHaA",
        "outputId": "00da7ddd-3a9c-4ea3-8904-d5500a101a99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "180040 30212 30135\n",
            "CPU times: user 568 ms, sys: 133 ms, total: 701 ms\n",
            "Wall time: 764 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Get data from file and preprocess it\n",
        "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
        "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\") # Validation data\n",
        "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
        "print(len(train_samples), len(val_samples), len(test_samples))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6uaro7gOHaA",
        "outputId": "e72014c0-bdff-4621-99ea-3bf3121cae1f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'target': 'OBJECTIVE',\n",
              "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              "  'line_number': 2,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              "  'line_number': 3,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              "  'line_number': 4,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              "  'line_number': 5,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              "  'line_number': 6,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              "  'line_number': 7,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              "  'line_number': 8,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'these differences remained significant at @ weeks .',\n",
              "  'line_number': 9,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
              "  'line_number': 10,\n",
              "  'total_lines': 11},\n",
              " {'target': 'CONCLUSIONS',\n",
              "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
              "  'line_number': 11,\n",
              "  'total_lines': 11},\n",
              " {'target': 'BACKGROUND',\n",
              "  'text': 'emotional eating is associated with overeating and the development of obesity .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 10},\n",
              " {'target': 'BACKGROUND',\n",
              "  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 10}]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the first abstract of our training data\n",
        "train_samples[:14]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kDZxKxWpOHaA",
        "outputId": "e0a0763d-52ec-4cce-fa49-ad2d2cbc5614"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ff46151b-4fca-4bd0-86c8-558810708983\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff46151b-4fca-4bd0-86c8-558810708983')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ff46151b-4fca-4bd0-86c8-558810708983 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ff46151b-4fca-4bd0-86c8-558810708983');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bb62b357-485d-4ee2-96a5-7785fd3adb11\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bb62b357-485d-4ee2-96a5-7785fd3adb11')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bb62b357-485d-4ee2-96a5-7785fd3adb11 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      target                                               text  line_number  \\\n",
              "0  OBJECTIVE  to investigate the efficacy of @ weeks of dail...            0   \n",
              "1    METHODS  a total of @ patients with primary knee oa wer...            1   \n",
              "2    METHODS  outcome measures included pain reduction and i...            2   \n",
              "3    METHODS  pain was assessed using the visual analog pain...            3   \n",
              "4    METHODS  secondary outcome measures included the wester...            4   \n",
              "\n",
              "   total_lines  \n",
              "0           11  \n",
              "1           11  \n",
              "2           11  \n",
              "3           11  \n",
              "4           11  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "test_df = pd.DataFrame(test_samples)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCxtFEZ4OHaB",
        "outputId": "3ed0de61-6c45-4d7b-be42-0e649a24da49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(180040, 30212, 30135)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert abstract text lines into lists\n",
        "train_sentences = train_df[\"text\"].tolist()\n",
        "val_sentences = val_df[\"text\"].tolist()\n",
        "test_sentences = test_df[\"text\"].tolist()\n",
        "len(train_sentences), len(val_sentences), len(test_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLMRBkLMOHaB",
        "outputId": "d0fc5c29-4c40-4138-83c2-7516ec4b042b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              " 'these differences remained significant at @ weeks .']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View the 10 lines of training sentences\n",
        "train_sentences[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfzasgP5OHaB",
        "outputId": "7bbac6bc-4327-45bd-9d55-1a7419d3db5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[0., 0., 0., 1., 0.],\n",
              "        [0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0.]]),\n",
              " array([[1., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0.]]),\n",
              " array([[1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        ...,\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 1., 0., 0., 0.]]))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# One hot encode labels\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse_output=False) # We want non-sparse matrix\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "\n",
        "train_labels_one_hot, val_labels_one_hot, test_labels_one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7jW8nazOHaB",
        "outputId": "c198e01e-ea78-4bb2-f315-3f34780e2df8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['OBJECTIVE', 'METHODS', 'METHODS', ..., 'RESULTS', 'CONCLUSIONS',\n",
              "       'CONCLUSIONS'], dtype=object)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df[\"target\"].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rujR_fq4OHaB",
        "outputId": "9f6779c9-cc7c-4c2d-cf04-f8036e6bfd4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([['OBJECTIVE'],\n",
              "       ['METHODS'],\n",
              "       ['METHODS'],\n",
              "       ...,\n",
              "       ['RESULTS'],\n",
              "       ['CONCLUSIONS'],\n",
              "       ['CONCLUSIONS']], dtype=object)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df[\"target\"].to_numpy().reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo-aeNdiOHaB",
        "outputId": "d756afe3-18a3-4b64-ad05-1219b0697321"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3, 2, 2, ..., 4, 1, 1])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Extract labels (\"target\" columns) and encode them into integers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
        "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
        "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())\n",
        "\n",
        "# Check what training labels look like\n",
        "train_labels_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nvDvChpOHaB",
        "outputId": "510e0739-fc83-4dfe-b96f-057283b54c80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5,\n",
              " array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get class names and number of classes from LabelEncoder instance\n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "\n",
        "num_classes, class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HVxpi08OHaB"
      },
      "source": [
        "## Creating a series of model experiments\n",
        "\n",
        "We've preprocessed our data so now, in true machine learning fashion, it's time to setup a series of modelling experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcvYRSwSOHaB"
      },
      "source": [
        "### 1. Checkout the Keras guide on using pretrained GloVe embeddings. Can you get this working with one of our models?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGFiYLphOHaB",
        "outputId": "5a7deba6-0081-47d2-e970-fb1bb682edbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-01-28 11:16:20--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2025-01-28 11:16:20--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2025-01-28 11:16:20--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n",
            "\n",
            "2025-01-28 11:19:00 (5.16 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Loading the pre-trained embeddings\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE0DpPUWOHaB",
        "outputId": "b67c82a7-257b-4979-9d87-033290391126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors\n"
          ]
        }
      ],
      "source": [
        "# Getting the path of the glove embedding (using 100D)\n",
        "import numpy as np\n",
        "glove_path = 'glove.6B.100d.txt'\n",
        "\n",
        "embedding_index = {}\n",
        "\n",
        "# Making dict of vector representtion of the words (s --> [8, 48......])\n",
        "with open(glove_path) as f:\n",
        "  for line in f:\n",
        "\n",
        "    # Getting the words and coef in a variable\n",
        "    word , coefs = line.split(maxsplit = 1)\n",
        "    coefs = np.fromstring(coefs , 'f' , sep = ' ')\n",
        "\n",
        "    # Adding the coefs to our embedding dict\n",
        "    embedding_index[word] = coefs\n",
        "\n",
        "print(f'Found {len(embedding_index)} word vectors')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9VRNo6uzOHaB"
      },
      "outputs": [],
      "source": [
        "# Make function to split sentences into characters\n",
        "def split_chars(text):\n",
        "  return \" \".join(list(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "xYfzzS9lOHaC"
      },
      "outputs": [],
      "source": [
        "train_sentences = train_df[\"text\"].tolist()\n",
        "val_sentences = val_df[\"text\"].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODDSqjrKOHaC",
        "outputId": "dd7a3211-2833-44af-90e4-607613dca199"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .',\n",
              " 'a   t o t a l   o f   @   p a t i e n t s   w i t h   p r i m a r y   k n e e   o a   w e r e   r a n d o m i z e d   @ : @   ;   @   r e c e i v e d   @   m g / d a y   o f   p r e d n i s o l o n e   a n d   @   r e c e i v e d   p l a c e b o   f o r   @   w e e k s   .',\n",
              " 'o u t c o m e   m e a s u r e s   i n c l u d e d   p a i n   r e d u c t i o n   a n d   i m p r o v e m e n t   i n   f u n c t i o n   s c o r e s   a n d   s y s t e m i c   i n f l a m m a t i o n   m a r k e r s   .',\n",
              " 'p a i n   w a s   a s s e s s e d   u s i n g   t h e   v i s u a l   a n a l o g   p a i n   s c a l e   (   @ - @   m m   )   .',\n",
              " 's e c o n d a r y   o u t c o m e   m e a s u r e s   i n c l u d e d   t h e   w e s t e r n   o n t a r i o   a n d   m c m a s t e r   u n i v e r s i t i e s   o s t e o a r t h r i t i s   i n d e x   s c o r e s   ,   p a t i e n t   g l o b a l   a s s e s s m e n t   (   p g a   )   o f   t h e   s e v e r i t y   o f   k n e e   o a   ,   a n d   @ - m i n   w a l k   d i s t a n c e   (   @ m w d   )   .']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Split sequence-level data splits into character-level data splits\n",
        "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
        "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
        "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
        "train_chars[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "b1ZqnMN0OHaC"
      },
      "outputs": [],
      "source": [
        "# Creatinga a text vectorizaiton layer (68k vocab size from the paper itself)\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens= 68000 ,\n",
        "                                    output_sequence_length = 56)\n",
        "\n",
        "# Adapt our text vectorizer to training sentences\n",
        "\n",
        "text_vectorizer.adapt(train_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1u_B2NSJOHaC",
        "outputId": "3fd74410-0513-429f-9508-46cae2d153b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "64841"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Getting the vocabulary of the vectorizer\n",
        "text_vocab = text_vectorizer.get_vocabulary()\n",
        "len(text_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "cJxGDeYiOHaC"
      },
      "outputs": [],
      "source": [
        "# Getting the dict mapping word ---> index\n",
        "word_index_text = dict(zip(text_vocab, range(len(text_vocab))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vGDi3FB1OHaC"
      },
      "outputs": [],
      "source": [
        "# Creating a function that will give us a embedding matrix\n",
        "def get_glove_embedding_matrix(num_tokens, embedding_dim, word_index):\n",
        "    # Defining the hits and misses here\n",
        "    hits, misses = 0, 0\n",
        "\n",
        "    # Prepare the embedding matrix\n",
        "    embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = embedding_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "            hits += 1\n",
        "        else:\n",
        "            misses += 1\n",
        "    return embedding_matrix, hits, misses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmGAA8T0OHaC",
        "outputId": "35ea23eb-4c67-41c6-e21e-73f3a03b70df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Length of embedding dim\n",
        "len(embedding_index.get('a'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "CE2bdlCTOHaD"
      },
      "outputs": [],
      "source": [
        "# Using the above function to get the embedding matrix\n",
        "num_tokens_text = len(text_vocab) + 2\n",
        "embedding_dim = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "mg1pXi5SOHaD"
      },
      "outputs": [],
      "source": [
        "sentence_embed_matrix, hits_, misses_ = get_glove_embedding_matrix(num_tokens=num_tokens_text, embedding_dim=embedding_dim, word_index=word_index_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnzWFJDsOHaD",
        "outputId": "f7eae305-5392-42a7-c8b1-d13946396cfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hits: 29730 and Misses: 35111 for the sentence embedding matrix\n"
          ]
        }
      ],
      "source": [
        "print(f'Hits: {hits_} and Misses: {misses_} for the sentence embedding matrix')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Fae4EZ6GOHaD"
      },
      "outputs": [],
      "source": [
        "# Adding the embedding matrix to our embedding layer\n",
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "sentence_embeded_layer = Embedding(num_tokens_text,\n",
        "                                   embedding_dim,\n",
        "                                   embeddings_initializer = tf.keras.initializers.Constant(sentence_embed_matrix),\n",
        "                                   trainable=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PLnBNLIOHaD",
        "outputId": "9bdc82bc-4b89-491e-ab90-d383c64c6953"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 56), dtype=tf.int64, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>,\n",
              " <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 56), dtype=tf.int64, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating the datasets for our both sentences and chars\n",
        "\n",
        "train_sentences_vectors = text_vectorizer(np.array([[sen] for sen in train_sentences])).numpy()\n",
        "val_sentences_vectors = text_vectorizer(np.array([[sen] for sen in val_sentences])).numpy()\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_sentences_vectors, train_labels_encoded))\n",
        "train_ds = train_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "validation_ds = tf.data.Dataset.from_tensor_slices((val_sentences_vectors, val_labels_encoded))\n",
        "validation_ds = validation_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_ds, validation_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdw-sTwZOHaD",
        "outputId": "cbfd3b86-7528-48ad-8198-3936cea45904"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 100)         6484300   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, None, 128)         64128     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, None, 128)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, None, 128)         82048     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPoolin  (None, None, 128)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, None, 128)         82048     \n",
            "                                                                 \n",
            " global_max_pooling1d (Glob  (None, 128)               0         \n",
            " alMaxPooling1D)                                                 \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6729681 (25.67 MB)\n",
            "Trainable params: 245381 (958.52 KB)\n",
            "Non-trainable params: 6484300 (24.74 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input = layers.Input(shape = (None,) , dtype = 'int64')\n",
        "glove_emb = sentence_embeded_layer(input)\n",
        "x = layers.Conv1D(128 , 5 , activation= 'relu' , padding = 'same')(glove_emb)\n",
        "x = layers.MaxPooling1D(5, padding = 'same')(x)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\" , padding = 'same')(x)\n",
        "x = layers.MaxPooling1D(5 , padding ='same')(x)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\" , padding = 'same')(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "output = layers.Dense(len(class_names) , activation= 'softmax')(x)\n",
        "\n",
        "glove_model = tf.keras.Model(input , output)\n",
        "glove_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bxem5Jl2OHaD",
        "outputId": "034d55f8-a706-48f1-bf23-64f57e05c001"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "5627/5627 [==============================] - 49s 8ms/step - loss: 0.6520 - accuracy: 0.7566 - val_loss: 0.5488 - val_accuracy: 0.7945\n",
            "Epoch 2/3\n",
            "5627/5627 [==============================] - 37s 7ms/step - loss: 0.5279 - accuracy: 0.8081 - val_loss: 0.5109 - val_accuracy: 0.8113\n",
            "Epoch 3/3\n",
            "5627/5627 [==============================] - 32s 6ms/step - loss: 0.4840 - accuracy: 0.8242 - val_loss: 0.5361 - val_accuracy: 0.8084\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fa5e26212d0>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compiling and fitting the model\n",
        "glove_model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                     optimizer = tf.keras.optimizers.Adam(),\n",
        "                     metrics = ['accuracy'])\n",
        "\n",
        "glove_model.fit(train_ds,\n",
        "                 epochs = 3 ,\n",
        "                 validation_data = validation_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdblCnrzPzZ9"
      },
      "source": [
        "## Try replacing the TensorFlow Hub Universal Sentence Encoder pretrained  embedding for the [TensorFlow Hub BERT PubMed expert] (a language model pretrained on PubMed texts) pretrained embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "FTZSSE8RQDhV"
      },
      "outputs": [],
      "source": [
        "# Loading in the both encoder and the preprocessing models\n",
        "import tensorflow_text as text\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "\n",
        "preprocessing_layer = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3' ,\n",
        "                                     trainable = False , name = 'pubmed_bert_preprocessor')\n",
        "\n",
        "bert_layer = hub.KerasLayer('https://tfhub.dev/google/experts/bert/pubmed/2' ,\n",
        "                            trainable = False ,\n",
        "                            name = 'bert_model_layer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDvxunF_3Mfg",
        "outputId": "1382d2a5-6623-46cf-918c-33106fb586dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bert embedding shape: {'pooled_output': <KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'bert_model_layer')>, 'sequence_output': <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, 'encoder_outputs': [<KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>], 'default': <KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'bert_model_layer')>}\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_sentences (InputLaye  [(None,)]                    0         []                            \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " pubmed_bert_preprocessor (  {'input_type_ids': (None,    0         ['input_sentences[0][0]']     \n",
            " KerasLayer)                 128),                                                                \n",
            "                              'input_mask': (None, 128)                                           \n",
            "                             , 'input_word_ids': (None,                                           \n",
            "                              128)}                                                               \n",
            "                                                                                                  \n",
            " bert_model_layer (KerasLay  {'pooled_output': (None, 7   1094822   ['pubmed_bert_preprocessor[0][\n",
            " er)                         68),                         41        0]',                          \n",
            "                              'sequence_output': (None,              'pubmed_bert_preprocessor[0][\n",
            "                              128, 768),                            1]',                          \n",
            "                              'encoder_outputs': [(None              'pubmed_bert_preprocessor[0][\n",
            "                             , 128, 768),                           2]']                          \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768)],                                                  \n",
            "                              'default': (None, 768)}                                             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 128)                  98432     ['bert_model_layer[0][13]']   \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 128)                  0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 5)                    645       ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109581318 (418.02 MB)\n",
            "Trainable params: 99077 (387.02 KB)\n",
            "Non-trainable params: 109482241 (417.64 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input = layers.Input(shape = [], dtype=tf.string, name=\"input_sentences\")\n",
        "bert_inputs=preprocessing_layer(input)\n",
        "bert_embedding=bert_layer(bert_inputs)\n",
        "print(f\"Bert embedding shape: {bert_embedding}\")\n",
        "x=layers.Dense(128, activation=\"relu\")(bert_embedding['pooled_output'])\n",
        "x = layers.Dropout(0.5)(x)\n",
        "output=layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
        "\n",
        "pubmed_bert_model = tf.keras.Model(input, output)\n",
        "pubmed_bert_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "bubHT5SI5Px-"
      },
      "outputs": [],
      "source": [
        "# Making datasets for the pubmed model\n",
        "\n",
        "train_sen_ds = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_encoded))\n",
        "train_sen_ds = train_sen_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_sen_ds = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_encoded))\n",
        "val_sen_ds = val_sen_ds.batch(32).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRHSXJegNsD1",
        "outputId": "69312387-e504-40cc-927d-95266027169f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 251s 420ms/step - loss: 0.6586 - accuracy: 0.7749 - val_loss: 0.4581 - val_accuracy: 0.8391\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 239s 425ms/step - loss: 0.5150 - accuracy: 0.8225 - val_loss: 0.4363 - val_accuracy: 0.8348\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 239s 426ms/step - loss: 0.4988 - accuracy: 0.8280 - val_loss: 0.4144 - val_accuracy: 0.8577\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fa52c62f290>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pubmed_bert_model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy() ,\n",
        "                          optimizer = tf.keras.optimizers.Adam(),\n",
        "                          metrics =['accuracy'])\n",
        "\n",
        "pubmed_bert_model.fit(train_sen_ds ,\n",
        "                      steps_per_epoch = int(0.1 * len(train_sen_ds)),\n",
        "                      epochs = 3 ,\n",
        "                      validation_data = val_sen_ds ,\n",
        "                      validation_steps = int(0.1 * len(val_sen_ds)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAJOh-reOHV3"
      },
      "source": [
        "## What happens if you were to merge our `line_number` and `total_lines` features for each sequence? For example, created a `X_of_Y` feature instead? Does this effect model performance?\n",
        "   *  Another example: `line_number=1` and `total_lines=11` turns into `line_of_X=1_of_11`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "3Tlx_i5xN8TV",
        "outputId": "32a30a7d-a737-4caf-a56f-362a57af92b6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-6b10f822-53f0-4e32-b6de-0821de1fd649\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "      <th>line_number_total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0_of_11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>1_of_11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>2_of_11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>3_of_11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>4_of_11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>5_of_11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>there was a clinically relevant reduction in t...</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>6_of_11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the mean difference between treatment arms ( @...</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>7_of_11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>further , there was a clinically relevant redu...</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>8_of_11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>these differences remained significant at @ we...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>9_of_11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b10f822-53f0-4e32-b6de-0821de1fd649')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6b10f822-53f0-4e32-b6de-0821de1fd649 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6b10f822-53f0-4e32-b6de-0821de1fd649');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7a6d2f25-8d2d-48ce-afc1-ec43a2214c79\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7a6d2f25-8d2d-48ce-afc1-ec43a2214c79')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7a6d2f25-8d2d-48ce-afc1-ec43a2214c79 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      target                                               text  line_number  \\\n",
              "0  OBJECTIVE  to investigate the efficacy of @ weeks of dail...            0   \n",
              "1    METHODS  a total of @ patients with primary knee oa wer...            1   \n",
              "2    METHODS  outcome measures included pain reduction and i...            2   \n",
              "3    METHODS  pain was assessed using the visual analog pain...            3   \n",
              "4    METHODS  secondary outcome measures included the wester...            4   \n",
              "5    METHODS  serum levels of interleukin @ ( il-@ ) , il-@ ...            5   \n",
              "6    RESULTS  there was a clinically relevant reduction in t...            6   \n",
              "7    RESULTS  the mean difference between treatment arms ( @...            7   \n",
              "8    RESULTS  further , there was a clinically relevant redu...            8   \n",
              "9    RESULTS  these differences remained significant at @ we...            9   \n",
              "\n",
              "   total_lines line_number_total  \n",
              "0           11           0_of_11  \n",
              "1           11           1_of_11  \n",
              "2           11           2_of_11  \n",
              "3           11           3_of_11  \n",
              "4           11           4_of_11  \n",
              "5           11           5_of_11  \n",
              "6           11           6_of_11  \n",
              "7           11           7_of_11  \n",
              "8           11           8_of_11  \n",
              "9           11           9_of_11  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Combining the total lines and line number into a new feature!\n",
        "train_df['line_number_total'] = train_df['line_number'].astype(str) + '_of_' + train_df['total_lines'].astype(str)\n",
        "val_df['line_number_total'] = val_df['line_number'].astype(str) + '_of_' + val_df['total_lines'].astype(str)\n",
        "\n",
        "train_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uZcjq4oY34Q",
        "outputId": "51696091-0b77-402c-ef82-152290a75571"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((180040, 460), (30212, 460))"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Perform one hot encoding on the train and transform the validation dataframe\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Creating an instance\n",
        "one_hot_encoder = OneHotEncoder()\n",
        "\n",
        "# Fitting on the training dataframe\n",
        "one_hot_encoder.fit(np.expand_dims(train_df['line_number_total'] , axis = 1))\n",
        "\n",
        "# Transforming both train and val df\n",
        "train_line_number_total_encoded = one_hot_encoder.transform(np.expand_dims(train_df['line_number_total'] , axis =1))\n",
        "val_line_number_total_encoded  = one_hot_encoder.transform(np.expand_dims(val_df['line_number_total'] , axis= 1))\n",
        "\n",
        "# Checking the shapes\n",
        "train_line_number_total_encoded.shape , val_line_number_total_encoded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "tn-9i561Y6p9"
      },
      "outputs": [],
      "source": [
        "# Converting the sparse object to array\n",
        "train_line_number_total_encoded = train_line_number_total_encoded.toarray()\n",
        "val_line_number_total_encoded = val_line_number_total_encoded.toarray()\n",
        "\n",
        "# Converting the datatype to int\n",
        "train_line_number_total_encoded = tf.cast(train_line_number_total_encoded , dtype= tf.int32)\n",
        "val_line_number_total_encoded = tf.cast(val_line_number_total_encoded , dtype= tf.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7fZAeqZYuJx",
        "outputId": "cac8a480-f7fb-4fbd-ab61-06dcd3f51e58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<_PrefetchDataset element_spec=((TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 460), dtype=tf.int32, name=None)), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>,\n",
              " <_PrefetchDataset element_spec=((TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 460), dtype=tf.int32, name=None)), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Making the performant datasets for our tribid model\n",
        "train_data = tf.data.Dataset.from_tensor_slices((train_sentences ,\n",
        "                                                 train_chars ,\n",
        "                                                 train_line_number_total_encoded))\n",
        "\n",
        "train_labels = tf.data.Dataset.from_tensor_slices(train_labels_encoded)\n",
        "\n",
        "val_data = tf.data.Dataset.from_tensor_slices((val_sentences ,\n",
        "                                               val_chars ,\n",
        "                                               val_line_number_total_encoded))\n",
        "\n",
        "val_labels = tf.data.Dataset.from_tensor_slices(val_labels_encoded)\n",
        "\n",
        "# Zipping the data and labels\n",
        "train_dataset = tf.data.Dataset.zip((train_data , train_labels))\n",
        "val_dataset = tf.data.Dataset.zip((val_data , val_labels))\n",
        "\n",
        "# Applying batch and prefetching\n",
        "train_dataset = train_dataset.batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset , val_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52u3K16PRUvP",
        "outputId": "fcd5becc-35e0-430b-a052-e909a5eb669b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)        [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " pubmed_bert_preprocessor (  {'input_type_ids': (None,    0         ['input_2[0][0]',             \n",
            " KerasLayer)                 128),                                   'input_3[0][0]']             \n",
            "                              'input_mask': (None, 128)                                           \n",
            "                             , 'input_word_ids': (None,                                           \n",
            "                              128)}                                                               \n",
            "                                                                                                  \n",
            " bert_model_layer (KerasLay  {'pooled_output': (None, 7   1094822   ['pubmed_bert_preprocessor[1][\n",
            " er)                         68),                         41        0]',                          \n",
            "                              'sequence_output': (None,              'pubmed_bert_preprocessor[1][\n",
            "                              128, 768),                            1]',                          \n",
            "                              'encoder_outputs': [(None              'pubmed_bert_preprocessor[1][\n",
            "                             , 128, 768),                           2]',                          \n",
            "                              (None, 128, 768),                      'pubmed_bert_preprocessor[2][\n",
            "                              (None, 128, 768),                     0]',                          \n",
            "                              (None, 128, 768),                      'pubmed_bert_preprocessor[2][\n",
            "                              (None, 128, 768),                     1]',                          \n",
            "                              (None, 128, 768),                      'pubmed_bert_preprocessor[2][\n",
            "                              (None, 128, 768),                     2]']                          \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768)],                                                  \n",
            "                              'default': (None, 768)}                                             \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)        [(None, 460)]                0         []                            \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 64)                   49216     ['bert_model_layer[1][13]']   \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 64)                   49216     ['bert_model_layer[2][13]']   \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 32)                   14752     ['input_4[0][0]']             \n",
            "                                                                                                  \n",
            " token_char_hybrid_embeddin  (None, 128)                  0         ['dense_4[0][0]',             \n",
            " g (Concatenate)                                                     'dense_5[0][0]']             \n",
            "                                                                                                  \n",
            " tribid_embeddings (Concate  (None, 160)                  0         ['dense_6[0][0]',             \n",
            " nate)                                                               'token_char_hybrid_embedding[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 160)                  0         ['tribid_embeddings[0][0]']   \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 128)                  20608     ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 5)                    645       ['dense_7[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109616678 (418.15 MB)\n",
            "Trainable params: 134437 (525.14 KB)\n",
            "Non-trainable params: 109482241 (417.64 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Buidling the tribid model using the functional api\n",
        "\n",
        "input_token=layers.Input(shape = [] , dtype =tf.string)\n",
        "bert_inputs_token=preprocessing_layer(input_token)\n",
        "bert_embedding_sentence=bert_layer(bert_inputs_token)\n",
        "output_token_sentence=layers.Dense(64 , activation = 'relu')(bert_embedding_sentence['pooled_output'])\n",
        "token_model = tf.keras.Model(input_token , output_token_sentence)\n",
        "\n",
        "input_char = layers.Input(shape = [] , dtype =tf.string)\n",
        "bert_inputs_char = preprocessing_layer(input_char)\n",
        "bert_embedding_char = bert_layer(bert_inputs_char)\n",
        "output_char = layers.Dense(64 , activation = 'relu')(bert_embedding_char['pooled_output'])\n",
        "char_model = tf.keras.Model(input_char , output_char)\n",
        "\n",
        "line_number_total_input = layers.Input(shape = (460,), dtype = tf.int32)\n",
        "dense = layers.Dense(32 , activation = 'relu')(line_number_total_input)\n",
        "total_line_number_model = tf.keras.Model(line_number_total_input , dense)\n",
        "\n",
        "# Concatenating the tokens amd chars output (Hybrid!!!)\n",
        "combined_embeddings = layers.Concatenate(name = 'token_char_hybrid_embedding')([token_model.output ,\n",
        "                                                                                char_model.output])\n",
        "\n",
        "# Combining the line_number_total to our hybrid model (Time for Tribid!!)\n",
        "z = layers.Concatenate(name = 'tribid_embeddings')([total_line_number_model.output ,\n",
        "                                                    combined_embeddings])\n",
        "\n",
        "# Adding a dense + dropout and creating our output layer\n",
        "dropout = layers.Dropout(0.5)(z)\n",
        "x = layers.Dense(128 , activation='relu')(dropout)\n",
        "output_layer = layers.Dense(5 , activation='softmax')(x)\n",
        "\n",
        "# Packing into a model\n",
        "tribid_model = tf.keras.Model(inputs = [token_model.input ,\n",
        "                                        char_model.input ,\n",
        "                                        total_line_number_model.input] ,\n",
        "                              outputs = output_layer)\n",
        "\n",
        "tribid_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "id": "lDOH9Qi9hl9E",
        "outputId": "b9a6105e-b275-4c6b-c4e9-66290d9f42a1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Plotting the model structure\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(tribid_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1S0FkXqhrSi",
        "outputId": "d036f842-aea9-463d-80b3-a5f9844fe8dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "281/281 [==============================] - 519s 2s/step - loss: 0.7045 - accuracy: 0.7477 - val_loss: 0.4283 - val_accuracy: 0.8504\n",
            "Epoch 2/3\n",
            "281/281 [==============================] - 505s 2s/step - loss: 0.4516 - accuracy: 0.8465 - val_loss: 0.3501 - val_accuracy: 0.8780\n",
            "Epoch 3/3\n",
            "281/281 [==============================] - 514s 2s/step - loss: 0.4014 - accuracy: 0.8569 - val_loss: 0.3191 - val_accuracy: 0.8896\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fa55e672310>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tribid_model.compile(loss= tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                     optimizer= tf.keras.optimizers.Adam() ,\n",
        "                     metrics = ['accuracy'])\n",
        "\n",
        "tribid_model.fit(train_dataset ,\n",
        "                 steps_per_epoch = int(0.1 * len(train_dataset)),\n",
        "                 epochs = 3 ,\n",
        "                 validation_steps = int(0.1 * len(val_dataset)),\n",
        "                 validation_data = val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiOi-TM_nZz8",
        "outputId": "cd6d6ed2-b857-4e7e-a18c-884fdb998947"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "473/473 [==============================] - 725s 2s/step - loss: 0.3086 - accuracy: 0.8906\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.30858784914016724, 0.890573263168335]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluating on the whole val data\n",
        "tribid_model.evaluate(val_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUJcTEucsxJ2"
      },
      "source": [
        "## 4. Train model_5 on all of the data in the training dataset for as many epochs until it stops improving."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5ORofb7nadq",
        "outputId": "0817b845-ba8b-4e62-bac7-9a3b089b85c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorShape([180040, 30]), TensorShape([180040, 30]))"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use TensorFlow to create one-hot-encoded tensors of our \"line_number\" column\n",
        "train_line_numbers_one_hot = tf.one_hot(train_df[\"line_number\"].to_numpy(), depth=30)\n",
        "val_line_numbers_one_hot = tf.one_hot(val_df[\"line_number\"].to_numpy(), depth=30)\n",
        "test_line_numbers_one_hot = tf.one_hot(test_df[\"line_number\"].to_numpy(), depth=30)\n",
        "\n",
        "# Use TensorFlow to create one-hot-encoded tensors of our \"total_lines\" column\n",
        "train_total_lines_one_hot = tf.one_hot(train_df[\"total_lines\"].to_numpy(), depth=30)\n",
        "val_total_lines_one_hot = tf.one_hot(val_df[\"total_lines\"].to_numpy(), depth=30)\n",
        "test_total_lines_one_hot = tf.one_hot(test_df[\"total_lines\"].to_numpy(), depth=30)\n",
        "\n",
        "# Download pretrained TensorFlow Hub USE\n",
        "import tensorflow_hub as hub\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        trainable=False,\n",
        "                                        name=\"universal_sentence_encoder\")\n",
        "\n",
        "# Check shape and samples of total lines one-hot tensor\n",
        "train_total_lines_one_hot.shape, train_line_numbers_one_hot.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhYr9uf_nabS",
        "outputId": "4dbd66b5-df99-47d9-886c-6f39b8a24c30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " token_inputs (InputLayer)   [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " char_inputs (InputLayer)    [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " universal_sentence_encoder  (None, 512)                  2567978   ['token_inputs[0][0]',        \n",
            "  (KerasLayer)                                            24         'char_inputs[0][0]']         \n",
            "                                                                                                  \n",
            " lambda (Lambda)             (None, 1, 512)               0         ['universal_sentence_encoder[1\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " bidirectional (Bidirection  (None, 64)                   139520    ['lambda[0][0]']              \n",
            " al)                                                                                              \n",
            "                                                                                                  \n",
            " token_char_hybrid_embeddin  (None, 576)                  0         ['universal_sentence_encoder[0\n",
            " g (Concatenate)                                                    ][0]',                        \n",
            "                                                                     'bidirectional[0][0]']       \n",
            "                                                                                                  \n",
            " line_number_input (InputLa  [(None, 30)]                 0         []                            \n",
            " yer)                                                                                             \n",
            "                                                                                                  \n",
            " total_lines_input (InputLa  [(None, 30)]                 0         []                            \n",
            " yer)                                                                                             \n",
            "                                                                                                  \n",
            " dense_12 (Dense)            (None, 256)                  147712    ['token_char_hybrid_embedding[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_10 (Dense)            (None, 32)                   992       ['line_number_input[0][0]']   \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 32)                   992       ['total_lines_input[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 256)                  0         ['dense_12[0][0]']            \n",
            "                                                                                                  \n",
            " token_char_positional_embe  (None, 320)                  0         ['dense_10[0][0]',            \n",
            " dding (Concatenate)                                                 'dense_11[0][0]',            \n",
            "                                                                     'dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " output_layer (Dense)        (None, 5)                    1605      ['token_char_positional_embedd\n",
            "                                                                    ing[0][0]']                   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 257088645 (980.72 MB)\n",
            "Trainable params: 290821 (1.11 MB)\n",
            "Non-trainable params: 256797824 (979.61 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Re-building the Model 5\n",
        "\n",
        "# 1. Token inputs\n",
        "token_inputs = layers.Input(shape=[], dtype=\"string\", name=\"token_inputs\")\n",
        "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
        "token_outputs = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
        "token_model = tf.keras.Model(inputs=token_inputs,\n",
        "                             outputs=token_embeddings)\n",
        "\n",
        "\n",
        "# 2. Char inputs\n",
        "char_inputs = layers.Input(shape= [], dtype=\"string\", name=\"char_inputs\")\n",
        "char_embeddings = tf_hub_embedding_layer(char_inputs)\n",
        "exp_layer = layers.Lambda(lambda x: tf.expand_dims(x , axis = 1))(char_embeddings)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(32))(exp_layer)\n",
        "char_model = tf.keras.Model(inputs=char_inputs,\n",
        "                            outputs=char_bi_lstm)\n",
        "\n",
        "# 3. Line numbers inputs\n",
        "line_number_inputs = layers.Input(shape=(30,), dtype=tf.int32, name=\"line_number_input\")\n",
        "x = layers.Dense(32, activation=\"relu\")(line_number_inputs)\n",
        "line_number_model = tf.keras.Model(inputs=line_number_inputs,\n",
        "                                   outputs=x)\n",
        "\n",
        "# 4. Total lines inputs\n",
        "total_lines_inputs = layers.Input(shape=(30,), dtype=tf.int32, name=\"total_lines_input\")\n",
        "y = layers.Dense(32, activation=\"relu\")(total_lines_inputs)\n",
        "total_line_model = tf.keras.Model(inputs=total_lines_inputs,\n",
        "                                  outputs=y)\n",
        "\n",
        "# 5. Combine token and char embeddings into a hybrid embedding\n",
        "combined_embeddings = layers.Concatenate(name=\"token_char_hybrid_embedding\")([token_model.output,\n",
        "                                                                              char_model.output])\n",
        "z = layers.Dense(256, activation=\"relu\")(combined_embeddings)\n",
        "z = layers.Dropout(0.5)(z)\n",
        "\n",
        "# 6. Combine positional embeddings with combined token and char embeddings into a tribrid embedding\n",
        "z = layers.Concatenate(name=\"token_char_positional_embedding\")([line_number_model.output,\n",
        "                                                                total_line_model.output,\n",
        "                                                                z])\n",
        "\n",
        "# 7. Create output layer\n",
        "output_layer = layers.Dense(5, activation=\"softmax\", name=\"output_layer\")(z)\n",
        "\n",
        "# 8. Put together model\n",
        "model_5 = tf.keras.Model(inputs=[line_number_model.input,\n",
        "                                 total_line_model.input,\n",
        "                                 token_model.input,\n",
        "                                 char_model.input],\n",
        "                         outputs=output_layer)\n",
        "\n",
        "\n",
        "\n",
        "# Summary of the model\n",
        "model_5.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDW5FDM0naZD",
        "outputId": "75e30827-4c47-44e1-b3ba-e8307b0d38ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<_PrefetchDataset element_spec=((TensorSpec(shape=(None, 30), dtype=tf.float32, name=None), TensorSpec(shape=(None, 30), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None)), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>,\n",
              " <_PrefetchDataset element_spec=((TensorSpec(shape=(None, 30), dtype=tf.float32, name=None), TensorSpec(shape=(None, 30), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None)), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create training and validation datasets (all four kinds of inputs)\n",
        "train_pos_char_token_data = tf.data.Dataset.from_tensor_slices((train_line_numbers_one_hot,\n",
        "                                                                train_total_lines_one_hot,\n",
        "                                                                train_sentences,\n",
        "                                                                train_chars))\n",
        "train_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot)\n",
        "train_pos_char_token_dataset = tf.data.Dataset.zip((train_pos_char_token_data, train_pos_char_token_labels))\n",
        "train_pos_char_token_dataset = train_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Validation dataset\n",
        "val_pos_char_token_data = tf.data.Dataset.from_tensor_slices((val_line_numbers_one_hot,\n",
        "                                                              val_total_lines_one_hot,\n",
        "                                                              val_sentences,\n",
        "                                                              val_chars))\n",
        "val_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_pos_char_token_dataset = tf.data.Dataset.zip((val_pos_char_token_data, val_pos_char_token_labels))\n",
        "val_pos_char_token_dataset = val_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Check input shapes\n",
        "train_pos_char_token_dataset, val_pos_char_token_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJG4IPQFtFyj"
      },
      "source": [
        "`tf.keras.callbacks.ModelCheckpoint` to save the model's best weights only.\n",
        "\n",
        "`tf.keras.callbacks.EarlyStopping` to stop the model from training once the validation loss has stopped improving for ~3 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "cYtH22S_naWz"
      },
      "outputs": [],
      "source": [
        "# Creating the callbacks\n",
        "check_filepath = 'best_weights/checkpoint.ckpt'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath= check_filepath ,\n",
        "                                                               save_weights_only = True ,\n",
        "                                                               save_best_only = True  ,\n",
        "                                                               save_freq = 'epoch' ,\n",
        "                                                               monitor = 'val_loss')\n",
        "\n",
        "\n",
        "## These callbacks together improve training efficiency and help the model achieve better generalization.\n",
        "\n",
        "# Training stops once the validation loss plateaus (does not improve by at least min_delta) for patience epochs.\n",
        "early_stopping  = tf.keras.callbacks.EarlyStopping(monitor= 'val_loss' ,\n",
        "                                                   patience = 5, min_delta = 0.3 , verbose = 1)\n",
        "\n",
        "# Reduces the learning rate when validation loss stops improving\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
        "                                                 factor=0.2, # Reduces the learning rate by a factor of 0.2 (i.e., multiplies the learning rate by 0.2)\n",
        "                                                 patience=2, # Waits for 2 consecutive epochs of no improvement in validation loss before reducing the learning rate\n",
        "                                                 verbose=1,\n",
        "                                                 min_lr=1e-7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri7TGE_1thA-",
        "outputId": "62d53d75-6153-479d-fbd0-ce1e7bb29561"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "5627/5627 [==============================] - 283s 48ms/step - loss: 0.9675 - accuracy: 0.8162 - val_loss: 0.9234 - val_accuracy: 0.8448 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "5627/5627 [==============================] - 248s 44ms/step - loss: 0.9296 - accuracy: 0.8454 - val_loss: 0.9136 - val_accuracy: 0.8518 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "5627/5627 [==============================] - 250s 44ms/step - loss: 0.9219 - accuracy: 0.8514 - val_loss: 0.9102 - val_accuracy: 0.8528 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "5627/5627 [==============================] - 241s 43ms/step - loss: 0.9167 - accuracy: 0.8554 - val_loss: 0.9054 - val_accuracy: 0.8574 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "5627/5627 [==============================] - 229s 41ms/step - loss: 0.9123 - accuracy: 0.8585 - val_loss: 0.9055 - val_accuracy: 0.8569 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "5627/5627 [==============================] - 238s 42ms/step - loss: 0.9097 - accuracy: 0.8602 - val_loss: 0.9037 - val_accuracy: 0.8593 - lr: 0.0010\n",
            "Epoch 6: early stopping\n"
          ]
        }
      ],
      "source": [
        "model_5.compile(loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing= 0.2) ,\n",
        "                    optimizer = tf.keras.optimizers.Adam() ,\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "history = model_5.fit(train_pos_char_token_dataset ,\n",
        "                      epochs = 50 ,\n",
        "                      validation_data = val_pos_char_token_dataset  ,\n",
        "                      callbacks = [early_stopping , model_checkpoint_callback ,\n",
        "                                   reduce_lr])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXglZsx276TR"
      },
      "source": [
        "## Write a function (or series of functions) to take a sample abstract string, preprocess it (in the same way our model has been trained), make a prediction on each sequence in the abstract and return the abstract in the format:\n",
        "\n",
        " * PREDICTED_LABEL: SEQUENCE\n",
        "\n",
        " * PREDICTED_LABEL: SEQUENCE\n",
        "\n",
        " * PREDICTED_LABEL: SEQUENCE\n",
        "\n",
        " * PREDICTED_LABEL: SEQUENCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "dBX46QC8oa7J"
      },
      "outputs": [],
      "source": [
        "from spacy.lang.en import English\n",
        "\n",
        "def preprocess_abstracts_sequences(example_abstracts, model):\n",
        "  abstracts = pd.DataFrame(example_abstracts)\n",
        "\n",
        "  nlp = English()\n",
        "\n",
        "  # New version of spaCy\n",
        "  sentencizer = nlp.add_pipe(\"sentencizer\") # Create sentence splitting pipeline object\n",
        "\n",
        "  # Create \"doc\" of parsed sequences, change index for a different abstract\n",
        "  doc = nlp(example_abstracts[0][\"abstract\"])\n",
        "  abstract_lines = [str(sent) for sent in list(doc.sents)] # Return detected sentences from doc in string type (not spaCy token type)\n",
        "\n",
        "  # Get total number of lines\n",
        "  total_lines_in_sample = len(abstract_lines)\n",
        "\n",
        "  # Go through each line in abstract and create a list of dictionaries containing features for each line\n",
        "  sample_lines = []\n",
        "  for i, line in enumerate(abstract_lines):\n",
        "    sample_dict = {}\n",
        "    sample_dict[\"text\"] = str(line)\n",
        "    sample_dict[\"line_number\"] = i\n",
        "    sample_dict[\"total_lines\"] = total_lines_in_sample - 1\n",
        "    sample_lines.append(sample_dict)\n",
        "\n",
        "\n",
        "  # Get all line_number value from sample abstract\n",
        "  test_abstract_line_numbers = [line[\"line_number\"] for line in sample_lines]\n",
        "\n",
        "  # One-hot encode to same depth as training data, so model accepts right input shape\n",
        "  test_abstract_line_numbers_one_hot = tf.one_hot(test_abstract_line_numbers, depth=30)\n",
        "\n",
        "\n",
        "  # Get all total_lines values from sample abstract\n",
        "  test_abstract_total_lines = [line[\"total_lines\"] for line in sample_lines]\n",
        "  # One-hot encode to same depth as training data, so model accepts right input shape\n",
        "  test_abstract_total_lines_one_hot = tf.one_hot(test_abstract_total_lines, depth=30)\n",
        "\n",
        "  # Split abstract lines into characters\n",
        "  abstract_chars = [split_chars(sentence) for sentence in abstract_lines]\n",
        "\n",
        "  test_abstract_pred_probs = model.predict(x=(test_abstract_line_numbers_one_hot,\n",
        "                                                   test_abstract_total_lines_one_hot,\n",
        "                                                   tf.constant(abstract_lines),\n",
        "                                                   tf.constant(abstract_chars)))\n",
        "\n",
        "  # Turn prediction probabilities into prediction classes\n",
        "  test_abstract_preds = tf.argmax(test_abstract_pred_probs, axis=1)\n",
        "\n",
        "  # Turn prediction class integers into string class names\n",
        "  test_abstract_pred_classes = [label_encoder.classes_[i] for i in test_abstract_preds]\n",
        "\n",
        "  # Visualize abstract lines and predicted sequence labels\n",
        "  for i, line in enumerate(abstract_lines):\n",
        "    print(f\"{test_abstract_pred_classes[i]}: {line}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rc2N8-6M7yKe",
        "outputId": "e700985d-804f-433a-fc77-b61e957775cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-01-28 12:44:10--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/skimlit_example_abstracts.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6737 (6.6K) [text/plain]\n",
            "Saving to: ‘skimlit_example_abstracts.json’\n",
            "\n",
            "skimlit_example_abs 100%[===================>]   6.58K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-01-28 12:44:11 (76.3 MB/s) - ‘skimlit_example_abstracts.json’ saved [6737/6737]\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'abstract': 'This RCT examined the efficacy of a manualized social intervention for children with HFASDs. Participants were randomly assigned to treatment or wait-list conditions. Treatment included instruction and therapeutic activities targeting social skills, face-emotion recognition, interest expansion, and interpretation of non-literal language. A response-cost program was applied to reduce problem behaviors and foster skills acquisition. Significant treatment effects were found for five of seven primary outcome measures (parent ratings and direct child measures). Secondary measures based on staff ratings (treatment group only) corroborated gains reported by parents. High levels of parent, child and staff satisfaction were reported, along with high levels of treatment fidelity. Standardized effect size estimates were primarily in the medium and large ranges and favored the treatment group.',\n",
              "  'source': 'https://pubmed.ncbi.nlm.nih.gov/20232240/',\n",
              "  'details': 'RCT of a manualized social treatment for high-functioning autism spectrum disorders'},\n",
              " {'abstract': \"Postpartum depression (PPD) is the most prevalent mood disorder associated with childbirth. No single cause of PPD has been identified, however the increased risk of nutritional deficiencies incurred through the high nutritional requirements of pregnancy may play a role in the pathology of depressive symptoms. Three nutritional interventions have drawn particular interest as possible non-invasive and cost-effective prevention and/or treatment strategies for PPD; omega-3 (n-3) long chain polyunsaturated fatty acids (LCPUFA), vitamin D and overall diet. We searched for meta-analyses of randomised controlled trials (RCT's) of nutritional interventions during the perinatal period with PPD as an outcome, and checked for any trials published subsequently to the meta-analyses. Fish oil: Eleven RCT's of prenatal fish oil supplementation RCT's show null and positive effects on PPD symptoms. Vitamin D: no relevant RCT's were identified, however seven observational studies of maternal vitamin D levels with PPD outcomes showed inconsistent associations. Diet: Two Australian RCT's with dietary advice interventions in pregnancy had a positive and null result on PPD. With the exception of fish oil, few RCT's with nutritional interventions during pregnancy assess PPD. Further research is needed to determine whether nutritional intervention strategies during pregnancy can protect against symptoms of PPD. Given the prevalence of PPD and ease of administering PPD measures, we recommend future prenatal nutritional RCT's include PPD as an outcome.\",\n",
              "  'source': 'https://pubmed.ncbi.nlm.nih.gov/28012571/',\n",
              "  'details': 'Formatting removed (can be used to compare model to actual example)'},\n",
              " {'abstract': 'Mental illness, including depression, anxiety and bipolar disorder, accounts for a significant proportion of global disability and poses a substantial social, economic and heath burden. Treatment is presently dominated by pharmacotherapy, such as antidepressants, and psychotherapy, such as cognitive behavioural therapy; however, such treatments avert less than half of the disease burden, suggesting that additional strategies are needed to prevent and treat mental disorders. There are now consistent mechanistic, observational and interventional data to suggest diet quality may be a modifiable risk factor for mental illness. This review provides an overview of the nutritional psychiatry field. It includes a discussion of the neurobiological mechanisms likely modulated by diet, the use of dietary and nutraceutical interventions in mental disorders, and recommendations for further research. Potential biological pathways related to mental disorders include inflammation, oxidative stress, the gut microbiome, epigenetic modifications and neuroplasticity. Consistent epidemiological evidence, particularly for depression, suggests an association between measures of diet quality and mental health, across multiple populations and age groups; these do not appear to be explained by other demographic, lifestyle factors or reverse causality. Our recently published intervention trial provides preliminary clinical evidence that dietary interventions in clinically diagnosed populations are feasible and can provide significant clinical benefit. Furthermore, nutraceuticals including n-3 fatty acids, folate, S-adenosylmethionine, N-acetyl cysteine and probiotics, among others, are promising avenues for future research. Continued research is now required to investigate the efficacy of intervention studies in large cohorts and within clinically relevant populations, particularly in patients with schizophrenia, bipolar and anxiety disorders.',\n",
              "  'source': 'https://pubmed.ncbi.nlm.nih.gov/28942748/',\n",
              "  'details': 'Effect of nutrition on mental health'},\n",
              " {'abstract': \"Hepatitis C virus (HCV) and alcoholic liver disease (ALD), either alone or in combination, count for more than two thirds of all liver diseases in the Western world. There is no safe level of drinking in HCV-infected patients and the most effective goal for these patients is total abstinence. Baclofen, a GABA(B) receptor agonist, represents a promising pharmacotherapy for alcohol dependence (AD). Previously, we performed a randomized clinical trial (RCT), which demonstrated the safety and efficacy of baclofen in patients affected by AD and cirrhosis. The goal of this post-hoc analysis was to explore baclofen's effect in a subgroup of alcohol-dependent HCV-infected cirrhotic patients. Any patient with HCV infection was selected for this analysis. Among the 84 subjects randomized in the main trial, 24 alcohol-dependent cirrhotic patients had a HCV infection; 12 received baclofen 10mg t.i.d. and 12 received placebo for 12-weeks. With respect to the placebo group (3/12, 25.0%), a significantly higher number of patients who achieved and maintained total alcohol abstinence was found in the baclofen group (10/12, 83.3%; p=0.0123). Furthermore, in the baclofen group, compared to placebo, there was a significantly higher increase in albumin values from baseline (p=0.0132) and a trend toward a significant reduction in INR levels from baseline (p=0.0716). In conclusion, baclofen was safe and significantly more effective than placebo in promoting alcohol abstinence, and improving some Liver Function Tests (LFTs) (i.e. albumin, INR) in alcohol-dependent HCV-infected cirrhotic patients. Baclofen may represent a clinically relevant alcohol pharmacotherapy for these patients.\",\n",
              "  'source': 'https://pubmed.ncbi.nlm.nih.gov/22244707/',\n",
              "  'details': 'Baclofen promotes alcohol abstinence in alcohol dependent cirrhotic patients with hepatitis C virus (HCV) infection'}]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "# Download and open example abstracts (copy and pasted from PubMed)\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/skimlit_example_abstracts.json\n",
        "\n",
        "with open(\"skimlit_example_abstracts.json\", \"r\") as f:\n",
        "  example_abstracts = json.load(f)\n",
        "\n",
        "example_abstracts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k2q7nkz8M5I",
        "outputId": "61fe1eba-7cf6-4e4b-8d4f-15030f4e7b01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n",
            "OBJECTIVE: This RCT examined the efficacy of a manualized social intervention for children with HFASDs.\n",
            "METHODS: Participants were randomly assigned to treatment or wait-list conditions.\n",
            "METHODS: Treatment included instruction and therapeutic activities targeting social skills, face-emotion recognition, interest expansion, and interpretation of non-literal language.\n",
            "METHODS: A response-cost program was applied to reduce problem behaviors and foster skills acquisition.\n",
            "METHODS: Significant treatment effects were found for five of seven primary outcome measures (parent ratings and direct child measures).\n",
            "METHODS: Secondary measures based on staff ratings (treatment group only) corroborated gains reported by parents.\n",
            "RESULTS: High levels of parent, child and staff satisfaction were reported, along with high levels of treatment fidelity.\n",
            "RESULTS: Standardized effect size estimates were primarily in the medium and large ranges and favored the treatment group.\n"
          ]
        }
      ],
      "source": [
        "preprocess_abstracts_sequences(example_abstracts, model_5)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tensorflow_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
